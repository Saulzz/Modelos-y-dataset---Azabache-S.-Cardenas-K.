{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1112c3ad",
   "metadata": {},
   "source": [
    "# Modelo Ligistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b431be",
   "metadata": {},
   "source": [
    "## Exploracion y limpieza de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8973ab4",
   "metadata": {},
   "source": [
    "### Carga, Limpieza y Eliminación de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bffedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloque 1 - Importamos las librerias necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd7862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevas dimensiones del DataFrame: (217, 112)\n"
     ]
    }
   ],
   "source": [
    "melb_df = pd.read_csv(\"Students_Data.csv\")\n",
    "melb_df.index += 1\n",
    "\n",
    "##Eliminas las filas que tenga NaN (nulo)\n",
    "melb_df = melb_df.dropna(axis=0)\n",
    "\n",
    "columnas_a_eliminar = [\n",
    "    'puntaje_interes_C',\n",
    "    'puntaje_interes_H',\n",
    "    'puntaje_interes_A',\n",
    "    'puntaje_interes_S',\n",
    "    'puntaje_interes_I',\n",
    "    'puntaje_interes_D',\n",
    "    'puntaje_interes_E',\n",
    "    \n",
    "    'puntaje_aptitud_C',\n",
    "    'puntaje_aptitud_H',\n",
    "    'puntaje_aptitud_A',\n",
    "    'puntaje_aptitud_S',\n",
    "    'puntaje_aptitud_I',\n",
    "    'puntaje_aptitud_D',\n",
    "    'puntaje_aptitud_E',\n",
    "\n",
    "    'perfil_interes_1_codigo', \n",
    "    'perfil_interes_2_codigo', \n",
    "    'perfil_aptitud_1_codigo', \n",
    "    'perfil_aptitud_2_codigo'\n",
    "]\n",
    "\n",
    "# 2. Verifica cuáles de esas columnas existen realmente en tu DataFrame.\n",
    "columnas_existentes = [col for col in columnas_a_eliminar if col in melb_df.columns]\n",
    "\n",
    "# 3. Si se encontraron columnas, se eliminaran.\n",
    "if columnas_existentes:\n",
    "    melb_df.drop(columns=columnas_existentes, inplace=True, errors='ignore')\n",
    "    print(\"Nuevas dimensiones del DataFrame:\", melb_df.shape)\n",
    "else:\n",
    "    print(\"Las columnas de código especificadas ya no se encuentran en el DataFrame.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd699ea",
   "metadata": {},
   "source": [
    "### Definición de Objetivos (Y), Codificación y Separación X/Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ecd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas encontradas para codificar: 14\n",
      "--- Separación y División en Entrenamiento/Prueba Completada ---\n",
      "Forma de X_train: (173, 98)\n",
      "Forma de Y_train: (173, 14)\n",
      "Forma de X_test:  (44, 98)\n",
      "Forma de Y_test:  (44, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = melb_df.copy()\n",
    "\n",
    "# Columnas objetivos a convertir\n",
    "columnas_objetivo = [\n",
    "    'perfil_interes_1_nombre', 'perfil_interes_2_nombre',\n",
    "    'perfil_aptitud_1_nombre', 'perfil_aptitud_2_nombre',\n",
    "    'carrera_interes_1', 'carrera_interes_2', 'carrera_interes_3',\n",
    "    'carrera_interes_4', 'carrera_interes_5', 'carrera_aptitud_1',\n",
    "    'carrera_aptitud_2', 'carrera_aptitud_3', 'carrera_aptitud_4',\n",
    "    'carrera_aptitud_5'\n",
    "]\n",
    "\n",
    "# Filtra para asegurarte de que solo usas columnas que existen\n",
    "columnas_existentes = [col for col in columnas_objetivo if col in df.columns]\n",
    "\n",
    "print(f\"Columnas encontradas para codificar: {len(columnas_existentes)}\")\n",
    "\n",
    "if columnas_existentes:\n",
    "    todos_los_valores = pd.concat([df[col].astype(str) for col in columnas_existentes]).unique()\n",
    "    le = LabelEncoder()\n",
    "    le.fit(todos_los_valores)\n",
    "\n",
    "    # 3. Aplica la transformación usando .loc para ser explícitos\n",
    "    for col in columnas_existentes:\n",
    "        # Usamos .loc[:, col] para indicar \"todas las filas, esta columna\"\n",
    "        df.loc[:, col] = le.transform(df[col].astype(str))\n",
    "\n",
    "else:\n",
    "    print(\"¡Advertencia! Ninguna de las columnas objetivo especificadas se encontró.\")\n",
    "\n",
    "\n",
    "# Filtra solo las columnas que realmente existen\n",
    "columnas_existentes = [col for col in columnas_objetivo if col in df.columns]\n",
    "\n",
    "# 2. Separa X (Características) e Y (Objetivos)\n",
    "Y = df[columnas_existentes]\n",
    "X = df.drop(columns=columnas_existentes)\n",
    "\n",
    "# 3. Divide los datos en Entrenamiento y Prueba (80/30)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "# 4. Muestra las dimensiones de los conjuntos creados\n",
    "print(\"--- Separación y División en Entrenamiento/Prueba Completada ---\")\n",
    "print(f\"Forma de X_train: {X_train.shape}\")\n",
    "print(f\"Forma de Y_train: {Y_train.shape}\")\n",
    "print(f\"Forma de X_test:  {X_test.shape}\")\n",
    "print(f\"Forma de Y_test:  {Y_test.shape}\")\n",
    "\n",
    "\n",
    "# 2. Convierte TODAS las columnas de Y_train e Y_test a tipo entero (int)\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "print(f\"Todas las columnos son de tipo entero :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689bd94e",
   "metadata": {},
   "source": [
    "### Escalar los Datos (StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a528572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escalando los datos X...\n",
      "¡Datos X escalados y listos!\n",
      "Forma de X_train_scaled: (173, 98)\n",
      "Forma de X_test_scaled: (44, 98)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Escalando los datos X...\")\n",
    "\n",
    "# 1. Crea la instancia del escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Ajusta el escalador CON X_train y transforma X_train\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 3. Transforma X_test usando el escalador YA AJUSTADO\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"¡Datos X escalados y listos!\")\n",
    "print(f\"Forma de X_train_scaled: {X_train_scaled.shape}\")\n",
    "print(f\"Forma de X_test_scaled: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6482873",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a6f4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando el entrenamiento del modelo Logistic Regression (Multi-Output)...\n",
      "¡Entrenamiento completado en 2.74 segundos!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import time\n",
    "\n",
    "# --- Asumiendo que X_train_scaled y Y_train existen ---\n",
    "\n",
    "print(\"\\nIniciando el entrenamiento del modelo Logistic Regression (Multi-Output)...\")\n",
    "\n",
    "# 1. Crea el modelo base: Logistic Regression\n",
    "#    - max_iter: Aumentamos las iteraciones para asegurar convergencia.\n",
    "#    - random_state: Para reproducibilidad.\n",
    "log_reg_base = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 2. Crea el 'envoltorio' para múltiples salidas\n",
    "modelo_lr = MultiOutputClassifier(log_reg_base, n_jobs=-1)\n",
    "\n",
    "# 3. Entrena el modelo 'envuelto' con los datos escalados\n",
    "start_time = time.time()\n",
    "modelo_lr.fit(X_train_scaled, Y_train) # ¡¡OJO: Usa X_train_scaled!!\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"¡Entrenamiento completado en {end_time - start_time:.2f} segundos!\")\n",
    "\n",
    "# --- Tu modelo 'modelo_lr' está entrenado ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a73d72",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5067477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Realizando predicciones con Logistic Regression...\n",
      "¡Predicciones completadas! Se generaron 44 predicciones.\n"
     ]
    }
   ],
   "source": [
    "# --- Asumiendo que modelo_lr y X_test_scaled existen ---\n",
    "\n",
    "print(\"\\nRealizando predicciones con Logistic Regression...\")\n",
    "\n",
    "# Realiza predicciones sobre los datos de prueba ESCALADOS\n",
    "Y_pred_lr = modelo_lr.predict(X_test_scaled) # ¡¡OJO: Usa X_test_scaled!!\n",
    "\n",
    "print(f\"¡Predicciones completadas! Se generaron {Y_pred_lr.shape[0]} predicciones.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518db239",
   "metadata": {},
   "source": [
    "### Validacion y Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6545b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluación del Modelo Logistic Regression ---\n",
      "\n",
      "--- Rendimiento Individual por Salida (Logistic Regression) ---\n",
      "  - perfil_interes_1_nombre: Acc=0.659, F1=0.639, P=0.632, R=0.659\n",
      "  - perfil_interes_2_nombre: Acc=0.295, F1=0.283, P=0.304, R=0.295\n",
      "  - perfil_aptitud_1_nombre: Acc=0.682, F1=0.651, P=0.636, R=0.682\n",
      "  - perfil_aptitud_2_nombre: Acc=0.341, F1=0.329, P=0.326, R=0.341\n",
      "  - carrera_interes_1: Acc=0.500, F1=0.446, P=0.472, R=0.500\n",
      "  - carrera_interes_2: Acc=0.477, F1=0.450, P=0.435, R=0.477\n",
      "  - carrera_interes_3: Acc=0.545, F1=0.519, P=0.602, R=0.545\n",
      "  - carrera_interes_4: Acc=0.477, F1=0.463, P=0.544, R=0.477\n",
      "  - carrera_interes_5: Acc=0.455, F1=0.432, P=0.518, R=0.455\n",
      "  - carrera_aptitud_1: Acc=0.500, F1=0.440, P=0.430, R=0.500\n",
      "  - carrera_aptitud_2: Acc=0.500, F1=0.430, P=0.392, R=0.500\n",
      "  - carrera_aptitud_3: Acc=0.523, F1=0.468, P=0.457, R=0.523\n",
      "  - carrera_aptitud_4: Acc=0.523, F1=0.479, P=0.486, R=0.523\n",
      "  - carrera_aptitud_5: Acc=0.568, F1=0.520, P=0.514, R=0.568\n",
      "\n",
      "--- Métricas Generales (Logistic Regression) ---\n",
      "Precisión Exacta (Exact Match): 0.0455 (4.55%)\n",
      "Accuracy Promedio:              0.5032\n",
      "F1-Score Promedio (Weighted):   0.4678\n",
      "Precision Promedio (Weighted):  0.4819\n",
      "Recall Promedio (Weighted):     0.5032\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Asumiendo que Y_test y Y_pred_lr existen ---\n",
    "\n",
    "print(\"\\n--- Evaluación del Modelo Logistic Regression ---\")\n",
    "\n",
    "# 1. Calcula la Precisión Exacta (Manual)\n",
    "exact_matches_lr = np.all(Y_test.values == Y_pred_lr, axis=1).sum()\n",
    "total_samples_lr = Y_test.shape[0]\n",
    "exact_match_accuracy_lr = exact_matches_lr / total_samples_lr\n",
    "\n",
    "# 2. Calcula las métricas para cada salida y sus promedios\n",
    "f1_list_lr, precision_list_lr, recall_list_lr, accuracy_list_lr = [], [], [], []\n",
    "\n",
    "print(\"\\n--- Rendimiento Individual por Salida (Logistic Regression) ---\")\n",
    "for i, col_name in enumerate(Y_test.columns):\n",
    "    y_true_col = Y_test.iloc[:, i]\n",
    "    y_pred_col = Y_pred_lr[:, i] # ¡¡OJO: Usa Y_pred_lr!!\n",
    "    \n",
    "    acc = accuracy_score(y_true_col, y_pred_col)\n",
    "    f1 = f1_score(y_true_col, y_pred_col, average='weighted', zero_division=0)\n",
    "    prec = precision_score(y_true_col, y_pred_col, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true_col, y_pred_col, average='weighted', zero_division=0)\n",
    "    \n",
    "    accuracy_list_lr.append(acc)\n",
    "    f1_list_lr.append(f1)\n",
    "    precision_list_lr.append(prec)\n",
    "    recall_list_lr.append(rec)\n",
    "    \n",
    "    print(f\"  - {col_name}: Acc={acc:.3f}, F1={f1:.3f}, P={prec:.3f}, R={rec:.3f}\")\n",
    "\n",
    "# 3. Imprime los resultados generales\n",
    "print(\"\\n--- Métricas Generales (Logistic Regression) ---\")\n",
    "print(f\"Precisión Exacta (Exact Match): {exact_match_accuracy_lr:.4f} ({exact_match_accuracy_lr * 100:.2f}%)\")\n",
    "print(f\"Accuracy Promedio:              {np.mean(accuracy_list_lr):.4f}\")\n",
    "print(f\"F1-Score Promedio (Weighted):   {np.mean(f1_list_lr):.4f}\")\n",
    "print(f\"Precision Promedio (Weighted):  {np.mean(precision_list_lr):.4f}\")\n",
    "print(f\"Recall Promedio (Weighted):     {np.mean(recall_list_lr):.4f}\")\n",
    "print(\"--------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
